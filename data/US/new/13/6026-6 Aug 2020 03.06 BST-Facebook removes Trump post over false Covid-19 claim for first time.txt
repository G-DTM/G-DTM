Facebook removes Trump post over false Covid-19 claim for first time
Video in which Trump wrongly said kids were 'almost immune' from illness also prompted Twitter to ban president's re-election campaign account
Facebook has removed a post from Donald Trump's page for spreading false information about the coronavirus, a first for the social media company that has been harshly criticized for repeatedly allowing the president to break its content rules.
The post included video of Trump falsely asserting that children were "almost immune from Covid-19" during an appearance on Fox News. There is evidence to suggest that children who contract Covid-19 generally experience milder symptoms than adults do. However, they are not immune, and some children have become severely ill or died from the disease.
"This video includes false claims that a group of people is immune from Covid-19 which is a violation of our policies around harmful Covid misinformation," a Facebook spokesperson said.
The Twitter account for Trump's re-election campaign, @TeamTrump, also posted the video, which Twitter said violated its rules. "The account owner will be required to remove the Tweet before they can Tweet again," a company spokesperson said of @TeamTrump.
During a press briefing on Wednesday afternoon, Trump repeated his false claims about children and the disease.
The removals are the latest in a recent string of enforcement actions by social media platforms against the president over violating content rules related to misinformation, hate speech and threats of violence.
Trump's presidential campaign and tenure in office have been defined by his aggressive use of social media platforms to spread racism, xenophobia, threats and misinformation. For years, the US-based social media platforms that enabled his broadcasts were hesitant to enforce their own rules against him.
But the combined crises of the coronavirus pandemic and widespread civil unrest over the police killing of George Floyd appear to have inspired greater resolve among social media executives, with Twitter and Twitch taking action against Trump for threatening protesters, spreading misinformation about voting and, in Twitch's case, using hate speech.
Facebook has been more reticent to take action against the president over his speech. When Trump quoted a 1960s racist police chief by posting, "When the looting starts the shooting starts" during the uprisings over the police killing of George Floyd, the statement was widely condemned as incitement to violence and removed by Twitter.
Facebook defended Trump's right to post the statement, however, prompting anger among Democrats and civil rights activists. The company said it considered the statement to be a warning rather than a threat, because it came from a state actor.
While Wednesday's post is the first time that Facebook has taken action against Trump's account for coronavirus misinformation stated by the president himself, earlier this year the company did remove a series of ads and an organic post by Trump that featured a symbol historically associated with Nazis and in July it removed a video Trump shared to his account promoting an unproven cure for coronavirus.
Courtney Parella, the deputy national press secretary for the Trump campaign, responded to Facebook's takedown with a statement that mischaracterized Trump's appearance on Fox News.
"The president was stating a fact that children are less susceptible to the coronavirus," Parella said. "Another day, another display of Silicon Valley's flagrant bias against this president, where the rules are only enforced in one direction. Social media companies are not the arbiters of truth."
The battle over misinformation on Facebook has proven politically contentious, with ongoing action for and against removal of content. Trump and the Republican party have repeatedly claimed without evidence that major tech companies are biased against conservatives.
On Wednesday, the same day of Facebook's most recent removal, a group of 20 state attorneys general released a letter calling on the company to prevent the spread of hate, harassment and disinformation. In antitrust hearings last week, Republican lawmakers repeatedly grilled Mark Zuckerberg over the same issue, claiming the platform should leave these posts up.
No evidence has emerged to suggest that tech company moderators (or the rules the tech companies ask them to enforce) display partisan political bias. Most of the platforms do have rules against hate speech, the incitement of violence and dangerous misinformation about Covid-19.
Kari Paul contributed reporting